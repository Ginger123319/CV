{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L8tFwOzumG4o"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score as f1\n",
        "from sklearn.metrics import top_k_accuracy_score\n",
        "\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from utils.model import *\n",
        "from utils.loss import *\n",
        "from utils.dataset import *\n",
        "\n",
        "from transformers import AutoTokenizer, get_cosine_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "TJ36btN_5mq4",
        "outputId": "3c4ff202-e574-4dfa-e454-65dd73b97cee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# hyperparameters\n",
        "train_pth = 'datasets/atc_data.csv'  # 含有source和target的csv文件\n",
        "label_pth = 'datasets/atc_label.csv' # 含有固定位置所有label的文件\n",
        "\n",
        "learning_rate = 1e-4    # 学习率\n",
        "fl_gamma = 2.5          # focal loss中gamma，gamma越大困难样本贡献的loss越大\n",
        "hidden_size = 1024      # 隐藏层大小\n",
        "nhead = 4               # 注意力头数\n",
        "num_layers = 6          # transformer encoder的层数\n",
        "af_margin = 0.3         # arcface的边缘，边缘越大不同种类间隔越大\n",
        "warmup_ratio = 0        # 遇热步数 / 训练总步数\n",
        "source_max_length = 64  # 输入的默认最大长度\n",
        "batch_size = 128        # 批量大小\n",
        "\n",
        "n_epochs = 30           # 总训练的epoch数量\n",
        "curr_epoch = 0          # 当前epoch，默认为0\n",
        "checkpoint_path = 'checkpoints/atc_model_20.pt' # 继续训练的路径\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KdosH5nX6-C",
        "outputId": "87c18e49-6886-4916-d29e-f5a5cca572bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "resume from checkpoints/atc_model_20.pt\n"
          ]
        }
      ],
      "source": [
        "from os.path import exists\n",
        "checkpoint_path = checkpoint_path if exists(checkpoint_path) else None\n",
        "print('resume from', checkpoint_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iuqNoa6umOGa"
      },
      "outputs": [],
      "source": [
        "atc_df = pd.read_csv(train_pth)\n",
        "atc_df.source = atc_df.source.str.strip().str.upper()\n",
        "# atc_df.drop_duplicates(inplace=True) # 根据情况决定是否去重"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pvNFwAItmqXQ"
      },
      "outputs": [],
      "source": [
        "# set the minimum of a label's count to be 3\n",
        "arr = np.array(Counter(atc_df.target).most_common())\n",
        "\n",
        "idx1 = np.where(arr[:,1].astype('int') == 1)[0]\n",
        "tgt1 = arr[idx1][:,0]\n",
        "\n",
        "idx2 = np.where(arr[:,1].astype('int') == 2)[0]\n",
        "tgt2 = arr[idx2][:,0]\n",
        "\n",
        "add_df1 = atc_df.query('target in @tgt1')\n",
        "add_df2 = atc_df.query('target in @tgt2')\n",
        "atc_df = pd.concat((atc_df, add_df1, add_df1, add_df2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_JpJvR2mpcEg"
      },
      "outputs": [],
      "source": [
        "# label encoding\n",
        "atc_label = pd.read_csv(label_pth)\n",
        "le = LabelEncoder()\n",
        "le.fit(atc_label.label)\n",
        "label_to_id = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "id_to_label = dict(zip(le.transform(le.classes_), le.classes_))\n",
        "\n",
        "atc_df.target = le.transform(atc_df.target)\n",
        "num_labels = len(set(atc_df.target))\n",
        "\n",
        "# save sorted label\n",
        "atc_label = pd.DataFrame({'label':label_to_id.keys(), 'id':label_to_id.values()})\n",
        "atc_label.to_csv(label_pth, index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "13-oDO-f9JpW"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('./tokenizer')\n",
        "# tokenizer.add_tokens(['A', 'B1', 'B2', 'B3', 'B5', 'B6', 'B7', 'B9', 'B12', 'C', 'D', 'E', 'K', 'TNF', 'α'])\n",
        "# tokenizer.save_pretrained('./tokenizer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fwbhgxmsoIsz"
      },
      "outputs": [],
      "source": [
        "X, y = atc_df.source.tolist(), atc_df.target.tolist()\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=20, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EDgMrbPBy4nK"
      },
      "outputs": [],
      "source": [
        "train_dataset = ATC_dataset(X, y, tokenizer, source_max_length, 'train', device)\n",
        "valid_dataset = ATC_dataset(X_valid, y_valid, tokenizer, source_max_length, 'valid', device)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=False)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "F0xdADjL7hi5"
      },
      "outputs": [],
      "source": [
        "model = Model(len(tokenizer), num_labels, hidden_size, nhead, num_layers, margin=af_margin).to(device)\n",
        "criterion = FocalLoss(fl_gamma)\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "if checkpoint_path is not None:\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    curr_epoch = checkpoint['epoch']\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "total_steps = (len(train_dataset) // batch_size) * (n_epochs - curr_epoch) + 1\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=int(total_steps * warmup_ratio), num_training_steps=total_steps, num_cycles=0.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BCcv9MtbSxWy"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_true, y_score, k):\n",
        "\n",
        "    if k == 1:  \n",
        "        return np.mean(y_true == y_score)\n",
        "    else:\n",
        "        return top_k_accuracy_score(y_true, y_score, k=k, labels=list(range(num_labels)))\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    return f1(y_true, y_pred, average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlungp8IrjvX",
        "outputId": "9f537a3e-69fa-440b-ed7a-12dd88d4c78d"
      },
      "outputs": [],
      "source": [
        "train_info = []\n",
        "val_info = []\n",
        "\n",
        "for epoch in range(curr_epoch, n_epochs):\n",
        "\n",
        "    model.train()   \n",
        "    train_loss = []\n",
        "    train_pbar = tqdm(train_loader)\n",
        "    train_count = len(train_loader)\n",
        "\n",
        "    for batch in train_pbar:\n",
        "        train_pbar.set_description_str(f'[ Train | {epoch + 1:03d}/{n_epochs:03d} ]')\n",
        "        \n",
        "        labels = batch['labels']\n",
        "        logits = model(batch)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        loss = loss.detach().item()\n",
        "        train_loss.append(loss)\n",
        "\n",
        "        train_count -= 1\n",
        "        if train_count > 0:\n",
        "            train_pbar.set_postfix_str(f'loss = {loss:.6f} lr = {scheduler.get_last_lr()[0]}')\n",
        "        else:     \n",
        "            train_avg_loss = sum(train_loss) / len(train_loss)\n",
        "            train_info.append([epoch, train_avg_loss])\n",
        "            train_pbar.set_postfix_str(f'average loss = {train_avg_loss:.6f}')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        val_acc_list = []\n",
        "        val_pbar = tqdm(valid_loader)\n",
        "        val_count = len(valid_loader)\n",
        "\n",
        "        for batch in val_pbar:\n",
        "            val_pbar.set_description_str(f'[ Valid | {epoch + 1:03d}/{n_epochs:03d} ]')\n",
        "            logits = model(batch)\n",
        "            preds = logits.argmax(1)\n",
        "            acc = (preds == batch['labels']).float().mean().item()\n",
        "            val_acc_list.append(acc)\n",
        "\n",
        "            val_count -= 1\n",
        "            if val_count > 0:\n",
        "                val_pbar.set_postfix_str(f'acc = {acc:.3f}')\n",
        "            else:\n",
        "                val_acc = np.mean(val_acc_list)\n",
        "                val_info.append([epoch, val_acc])\n",
        "                val_pbar.set_postfix_str(f'average accuracy = {val_acc:.5f}')\n",
        "\n",
        "    checkpoint = {\n",
        "        'epoch': epoch + 1,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict()\n",
        "    }\n",
        "    torch.save(checkpoint, f'checkpoints/atc_model_{epoch + 1}.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0H-OygfxKfaT"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load(f'checkpoints/atc_model_{n_epochs}.pt')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "torch.save(model, f'models/atc_model_{n_epochs}.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOLnxEYb59Yv"
      },
      "outputs": [],
      "source": [
        "atc_clean_df = pd.read_csv('datasets/atc_clean.csv')\n",
        "atc_clean_df.drop_duplicates(inplace=True)\n",
        "atc_clean_df.target = le.transform(atc_clean_df.target)\n",
        "X_clean, y_clean = atc_clean_df.source.tolist(), atc_clean_df.target.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFSo8qBZBPMP",
        "outputId": "829f2236-e71f-4a59-bdbd-988c47eef87c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8426/8426 [08:30<00:00, 16.50it/s]\n",
            "100%|██████████| 2107/2107 [02:07<00:00, 16.55it/s]\n",
            "100%|██████████| 1863/1863 [01:52<00:00, 16.56it/s]\n"
          ]
        }
      ],
      "source": [
        "def predict(model, texts):\n",
        "    texts = [text.strip().upper() for text in texts]\n",
        "    dataset = ATC_dataset(texts, None, 'predict')\n",
        "    dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "    model.eval()\n",
        "    logits_list = []\n",
        "\n",
        "    for batch in tqdm(dataloader):\n",
        "        logits_list.append(model(batch).cpu().detach().numpy())\n",
        "    return np.vstack(logits_list)\n",
        "\n",
        "train_logits = predict(model, X_train)\n",
        "valid_logits = predict(model, X_valid)\n",
        "clean_logits = predict(model, X_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoOK0FDeMoJB",
        "outputId": "7ecd059d-d6b8-4b3b-fb33-dd94942570e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train accuracy      : 0.9926\n",
            "Train top 2 accuracy: 0.9999\n",
            "Train top 3 accuracy: 1.0000\n",
            "Train f1            : 0.9925\n",
            "Valid accuracy      : 0.9904\n",
            "Valid top 2 accuracy: 0.9999\n",
            "Valid top 3 accuracy: 1.0000\n",
            "Valid f1            : 0.9900\n",
            "Clean accuracy      : 0.9628\n",
            "Clean top 2 accuracy: 0.9986\n",
            "Clean top 3 accuracy: 0.9996\n",
            "Clean f1            : 0.9615\n"
          ]
        }
      ],
      "source": [
        "def print_predict_info(y_true, logits_list, title):\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = logits_list.argmax(1)\n",
        "\n",
        "    acc1 = np.mean(y_true == y_pred)\n",
        "    print(f'{title} accuracy      : {acc1:.04f}')\n",
        "\n",
        "    acc2 = accuracy(y_true, logits_list, 2)\n",
        "    print(f'{title} top 2 accuracy: {acc2:.04f}')\n",
        "\n",
        "    acc3 = accuracy(y_true, logits_list, 3)\n",
        "    print(f'{title} top 3 accuracy: {acc3:.04f}')\n",
        "\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    print(f'{title} f1            : {f1:.04f}')\n",
        "\n",
        "print_predict_info(y_train, train_logits, 'Train')\n",
        "print_predict_info(y_valid, valid_logits, 'Valid')\n",
        "print_predict_info(y_clean, clean_logits, 'Clean')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "atc_trainer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
