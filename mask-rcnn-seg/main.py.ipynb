{
	"nbformat_minor":2,
	"metadata":{
		"language_info":{
			"pygments_lexer":"ipython3",
			"nbconvert_exporter":"python",
			"codemirror_mode":{
				"name":"ipython",
				"version":3
			},
			"name":"python",
			"file_extension":".py",
			"mimetype":"text/x-python",
			"version":"3.7.4"
		},
		"kernelspec":{
			"name":"python3",
			"language":"python",
			"display_name":"Python 3"
		}
	},
	"cells":[
		{
			"outputs":[
				{
					"output_type":"stream",
					"name":"stdout",
					"text":[
						"Aps is ready!\n",
						"pre_training_weights has been loaded!\n",
						"2021-08-24 17:55:04 INFO [model_repo] [140705841473344-/opt/pylib/dc_mrsdk.zip/dc_model_repo/step/userdefined_step.py:29] ===== 检测到自定义Transformer类[model_nets.mask_estimator.MaskRCNNEstimator]的源码路径为[/opt/aps/workdir/model_nets] [这是个目录]\n",
						"2021-08-24 17:55:04 INFO [model_repo] [140705841473344-/opt/pylib/dc_mrsdk.zip/dc_model_repo/step/base.py:598] ===== 对象model没有fit方法, obj=None\n",
						"2021-08-24 17:55:04 INFO [model_repo] [140705841473344-/opt/pylib/dc_mrsdk.zip/dc_model_repo/step/base.py:253] ===== 训练消耗1.121毫秒, 模型信息:\n",
						"\n",
						"2021-08-24 17:55:04 WARNING [model_repo] [140705841473344-/opt/pylib/dc_mrsdk.zip/dc_model_repo/step/base.py:258] ===== 当前DCStep的params信息为空，如果为自定义DCStep，可以覆盖实现get_params方法提供参数信息。\n"
					]
				},
				{
					"ename":"UnboundLocalError",
					"output_type":"error",
					"evalue":"Caught UnboundLocalError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/site-packages/torch/utils/data/dataset.py\", line 272, in __getitem__\n    return self.dataset[self.indices[idx]]\n  File \"/opt/aps/workdir/model_nets/tv_training_code.py\", line 55, in __getitem__\n    mask[mask == 255] = 0\nUnboundLocalError: local variable 'mask' referenced before assignment\n",
					"traceback":[
						"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
						"\u001B[0;31mUnboundLocalError\u001B[0m                         Traceback (most recent call last)",
						"\u001B[0;32m<ipython-input-6-b7b42b97a7a0>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[0munet_estimator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtfrecord_dir\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtfrecord_dir\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     75\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 76\u001B[0;31m \u001B[0munet_estimator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     77\u001B[0m \u001B[0munet_estimator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[0;31m# unet_estimator.persist()\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
						"\u001B[0;32m/opt/aps/workdir/model_nets/mask_estimator.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, **kwargs)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m         tv_training_code.train(self.device, self.num_classes, self.val_size, self.batch_size, self.lr, self.optimizer,  self.total_epoch, \n\u001B[0;32m---> 38\u001B[0;31m             self.dataset_path, self.class_name, self.model_output_path, self.pth_path, self.tensorboard_dir, self.work_dir, self.tfrecord_dir)\n\u001B[0m\u001B[1;32m     39\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
						"\u001B[0;32m/opt/aps/workdir/model_nets/tv_training_code.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(device, num_classes, val_size, batch_size, lr, optimizer, total_epoch, dataset_path, class_name, model_output_path, pth_path, tensorboard_dir, work_dir, tfrecord_dir)\u001B[0m\n\u001B[1;32m    181\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    182\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum_epochs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 183\u001B[0;31m         \u001B[0mmetric_logger\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_one_epoch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepoch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    184\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"train loss: \"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mround\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmetric_logger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mglobal_avg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'  epoch: '\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepoch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    185\u001B[0m         \u001B[0mtrain_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mround\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmetric_logger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mglobal_avg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
						"\u001B[0;32m/opt/aps/workdir/model_nets/detection/engine.py\u001B[0m in \u001B[0;36mtrain_one_epoch\u001B[0;34m(model, optimizer, data_loader, device, epoch, print_freq)\u001B[0m\n\u001B[1;32m     24\u001B[0m         \u001B[0mlr_scheduler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwarmup_lr_scheduler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwarmup_iters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwarmup_factor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mimages\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtargets\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmetric_logger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlog_every\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprint_freq\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mheader\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m         \u001B[0mimages\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mimage\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mimages\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m         \u001B[0mtargets\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mv\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m}\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtargets\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
						"\u001B[0;32m/opt/aps/workdir/model_nets/detection/utils.py\u001B[0m in \u001B[0;36mlog_every\u001B[0;34m(self, iterable, print_freq, header)\u001B[0m\n\u001B[1;32m    209\u001B[0m             ])\n\u001B[1;32m    210\u001B[0m         \u001B[0mMB\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m1024.0\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;36m1024.0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 211\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0mobj\u001B[0m \u001B[0;32min\u001B[0m \u001B[0miterable\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    212\u001B[0m             \u001B[0mdata_time\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mend\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    213\u001B[0m             \u001B[0;32myield\u001B[0m \u001B[0mobj\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
						"\u001B[0;32m/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    433\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sampler_iter\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    434\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 435\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    436\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    437\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
						"\u001B[0;32m/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1083\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1084\u001B[0m                 \u001B[0;32mdel\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_task_info\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1085\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_process_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1086\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1087\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_try_put_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
						"\u001B[0;32m/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_process_data\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m   1109\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_try_put_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1110\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mExceptionWrapper\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1111\u001B[0;31m             \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreraise\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1112\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1113\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
						"\u001B[0;32m/usr/local/lib/python3.7/site-packages/torch/_utils.py\u001B[0m in \u001B[0;36mreraise\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    426\u001B[0m             \u001B[0;31m# have message field\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    427\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexc_type\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmessage\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 428\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexc_type\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    429\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    430\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
						"\u001B[0;31mUnboundLocalError\u001B[0m: Caught UnboundLocalError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/site-packages/torch/utils/data/dataset.py\", line 272, in __getitem__\n    return self.dataset[self.indices[idx]]\n  File \"/opt/aps/workdir/model_nets/tv_training_code.py\", line 55, in __getitem__\n    mask[mask == 255] = 0\nUnboundLocalError: local variable 'mask' referenced before assignment\n"
					]
				}
			],
			"metadata":{
				"id":"BWORtNwP"
			},
			"execution_count":6,
			"source":[
				"import os\n",
				"import pandas as pd\n",
				"import json\n",
				"import shutil\n",
				"import torch \n",
				"\n",
				"from script_files import training_utils\n",
				"from model_nets.mask_estimator import MaskRCNNEstimator\n",
				"\n",
				"from datacanvas.aps import dc \n",
				"dc.logger.info(\"Aps is ready!\")\n",
				"\n",
				"# 读入数据\n",
				"# df_train = dc.dataset(dc.conf.inputs.train_data).read()\n",
				"# df_test = dc.dataset(dc.conf.inputs.test_data).read()\n",
				"# df_train = df_train.reset_index().drop('index', axis=1)\n",
				"# df_test = df_test.reset_index().drop('index', axis=1)\n",
				"# x_train = df_train.drop('classes', axis=1)\n",
				"# y_train = df_train['classes']\n",
				"# x_test = df_test.drop('classes', axis=1)\n",
				"# y_test = df_test['classes']\n",
				"x_train = pd.DataFrame([['abc.jpbg', 'ignore']], columns=['image_name', 'classes'])\n",
				"y_train = x_train['classes']\n",
				"x_train = x_train.drop(['classes'], axis=1)\n",
				"ds = dc.dataset(dc.conf.inputs.image_data)\n",
				"tfrecord_dir = str(dc.conf.inputs.image_data) + '/Horse_Person_tfrecord'\n",
				"csv_path = str(dc.conf.inputs.image_data) + '/Horse_Person_tfrecord/info.csv'\n",
				"\n",
				"\n",
				"os.system('mkdir ' + dc.conf.outputs.model_dir)\n",
				"os.system('mkdir ' + dc.conf.outputs.prediction)\n",
				"os.system('mkdir ' + dc.conf.outputs.best_model_dir)\n",
				"dataset_path = dc.conf.inputs.image_data+\"/data\"\n",
				"work_dir = '/tmp'\n",
				"tensorboard_dir = str(dc.conf.outputs.train_logs)\n",
				"num_classes = 1+2\n",
				"val_size = 0.1\n",
				"lr = 0.0001\n",
				"total_epoch = 2\n",
				"batch_size = 2\n",
				"optimizer = 'Adam'\n",
				"pth_logs_dir = str(dc.conf.outputs.model_dir)\n",
				"n_weights_saved = 3\n",
				"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
				"class_name = ['background', 'person', 'horse']\n",
				"model_output_path = str(dc.conf.outputs.best_model_dir)\n",
				"pth_path = work_dir + '/pre_training_weights/pre_training_weights.pth'\n",
				"\n",
				"# 生成用于保存训练过程中产生中间结果的目录\n",
				"# 生成各个图片中所包含类别的txt文件\n",
				"# training_utils.make_classname_dir(work_dir, dataset_path)\n",
				"# 保存预训练权重\n",
				"training_utils.load_pre_training_weights('maskrcnn_coco.pth', work_dir)\n",
				"\n",
				"\n",
				"# 实例化Estimator\n",
				"unet_estimator = MaskRCNNEstimator(input_cols=['image_name'], target_cols=['classes'], output_cols=['prediction'])\n",
				"unet_estimator.dataset_path = dataset_path\n",
				"unet_estimator.val_size = val_size\n",
				"unet_estimator.work_dir = work_dir\n",
				"unet_estimator.num_classes = num_classes\n",
				"unet_estimator.tensorboard_dir = tensorboard_dir\n",
				"\n",
				"unet_estimator.lr = lr\n",
				"unet_estimator.total_epoch = total_epoch\n",
				"unet_estimator.batch_size = batch_size\n",
				"unet_estimator.optimizer = optimizer\n",
				"unet_estimator.pth_logs_dir = pth_logs_dir\n",
				"unet_estimator.n_weights_saved = n_weights_saved\n",
				"unet_estimator.device = device\n",
				"unet_estimator.class_name = class_name\n",
				"unet_estimator.model_output_path = model_output_path\n",
				"unet_estimator.pth_path = pth_path\n",
				"unet_estimator.tfrecord_dir = tfrecord_dir\n",
				"\n",
				"unet_estimator.fit(x_train, y_train)\n",
				"unet_estimator.predict(x_train)\n",
				"# unet_estimator.persist()\n",
				"\n",
				"\n",
				"# 评估\n",
				"# best_model = get_miou_prediction.miou_predict(work_dir, dataset_path)\n",
				"# performance = miou.evaluate_miou(work_dir, dataset_path, num_classes)\n",
				"\n",
				"# # 输出结果\n",
				"# # performance\n",
				"# with open(dc.conf.outputs.performance, 'w') as f:\n",
				"#     json.dump(performance, f)\n",
				"\n",
				"# best_model_dir\n",
				"\n",
				"# shutil.copyfile(work_dir+'/middle_dir/normal_train_best_model_dir/'+best_model, dc.conf.outputs.best_model_dir+'/'+best_model)\n",
				"\n",
				"dc.logger.info(\"Done!\")\n",
				""
			],
			"cell_type":"code"
		}
	],
	"nbformat":4
}