{
	"nbformat_minor":2,
	"metadata":{
		"language_info":{
			"pygments_lexer":"ipython3",
			"nbconvert_exporter":"python",
			"codemirror_mode":{
				"name":"ipython",
				"version":3
			},
			"name":"python",
			"file_extension":".py",
			"mimetype":"text/x-python",
			"version":"3.7.4"
		},
		"kernelspec":{
			"name":"python3",
			"language":"python",
			"display_name":"Python 3"
		}
	},
	"cells":[
		{
			"cell_type":"code",
			"execution_count":1,
			"metadata":{
				"collapsed":false,
				"id":"EHP454Gu"
			},
			"outputs":[],
			"source":[
				"# Sample code from the TorchVision 0.3 Object Detection Finetuning Tutorial\n",
				"# http://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\n",
				"\n",
				"import os\n",
				"import numpy as np\n",
				"import torch\n",
				"from PIL import Image\n",
				"import cv2\n",
				"import random\n",
				"from pathlib import Path\n",
				"import io \n",
				"import pandas as pd \n",
				"import tensorflow as tf\n",
				"import xml.etree.ElementTree as ET\n",
				"\n",
				"import torchvision\n",
				"from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
				"from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
				"\n",
				"from .detection.engine import train_one_epoch, evaluate\n",
				"from .detection import utils\n",
				"from .detection import transforms as T\n",
				"from . import cv2_util\n",
				"\n",
				"from tensorboardX import SummaryWriter\n",
				"\n",
				"class InsSegDataset(object):\n",
				"    def __init__(self, transforms, tf_ds, class_name, dataset_len):\n",
				"        self.transforms = transforms\n",
				"        self.tf_ds = tf_ds\n",
				"        self.class_name = class_name\n",
				"        self.dataset_len = dataset_len\n",
				"        # Create a dictionary describing the tfrecord features.\n",
				"        self.image_feature_description = {\n",
				"            'image': tf.io.FixedLenFeature([], tf.string),\n",
				"            'label': tf.io.FixedLenFeature([], tf.string),\n",
				"            'mask': tf.io.FixedLenFeature([], tf.string),\n",
				"        }\n",
				"\n",
				"    def __getitem__(self, idx):\n",
				"        for i, e in enumerate(self.tf_ds):\n",
				"            if i == idx:\n",
				"                ee = _parse_image_function(e, self.image_feature_description)\n",
				"                img = Image.open(io.BytesIO(ee['image'].numpy())).convert(\"RGB\")\n",
				"                mask = np.array(Image.open(io.BytesIO(ee['mask'].numpy())))\n",
				"                label_root = ET.parse(io.BytesIO(ee['label'].numpy())).getroot()\n",
				"                object_name = []\n",
				"                for obj in label_root.iter('object'):\n",
				"                    cls = obj.find('name').text\n",
				"                    object_name.append(cls)\n",
				"                labels = [self.class_name.index(j) for j in object_name]\n",
				"                break\n",
				"\n",
				"        # 删除mask中的白色部分\n",
				"        mask[mask == 255] = 0\n",
				"        # instances are encoded as different colors\n",
				"        obj_ids = np.unique(mask)\n",
				"        # first id is the background, so remove it\n",
				"        obj_ids = obj_ids[1:]\n",
				"        # split the color-encoded mask into a set of binary masks\n",
				"        masks = mask == obj_ids[:, None, None]\n",
				"        # get bounding box coordinates for each mask\n",
				"        num_objs = len(obj_ids)\n",
				"        boxes = []\n",
				"        for i in range(num_objs):\n",
				"            pos = np.where(masks[i])\n",
				"            xmin = np.min(pos[1])\n",
				"            xmax = np.max(pos[1])\n",
				"            ymin = np.min(pos[0])\n",
				"            ymax = np.max(pos[0])\n",
				"            boxes.append([xmin, ymin, xmax, ymax])\n",
				"\n",
				"        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
				"        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
				"        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
				"        image_id = torch.tensor([idx])\n",
				"        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
				"        # suppose all instances are not crowd\n",
				"        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
				"\n",
				"        target = {}\n",
				"        target[\"boxes\"] = boxes\n",
				"        target[\"labels\"] = labels\n",
				"        target[\"masks\"] = masks\n",
				"        target[\"image_id\"] = image_id\n",
				"        target[\"area\"] = area\n",
				"        target[\"iscrowd\"] = iscrowd\n",
				"\n",
				"        if self.transforms is not None:\n",
				"            img, target = self.transforms(img, target)\n",
				"\n",
				"        return img, target\n",
				"\n",
				"    def __len__(self):\n",
				"        return self.dataset_len\n",
				"\n",
				"\n",
				"def get_model_instance_segmentation(num_classes, device, pth_path):\n",
				"\n",
				"    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=False, pretrained_backbone=False)\n",
				"    model_dict = model.state_dict()\n",
				"    pretrained_dict = torch.load(pth_path, map_location=device)\n",
				"    pretrained_dict = {k: v for k, v in pretrained_dict.items() if np.shape(model_dict[k]) == np.shape(v)}\n",
				"    model_dict.update(pretrained_dict)\n",
				"    model.load_state_dict(model_dict)\n",
				"\n",
				"    # get number of input features for the classifier\n",
				"    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
				"    # replace the pre-trained head with a new one\n",
				"    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
				"    # now get the number of input features for the mask classifier\n",
				"    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
				"    hidden_layer = 256\n",
				"    # and replace the mask predictor with a new one\n",
				"    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
				"\n",
				"    return model\n",
				"\n",
				"\n",
				"def get_transform(train):\n",
				"    \n",
				"    transforms = []\n",
				"    transforms.append(T.ToTensor())\n",
				"    if train:\n",
				"        transforms.append(T.RandomHorizontalFlip(0.5))\n",
				"        \n",
				"    return T.Compose(transforms)\n",
				"\n",
				"\n",
				"def toTensor(img):\n",
				"    \n",
				"    assert type(img) == np.ndarray, 'the img type is {}, but ndarry expected'.format(type(img))\n",
				"    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
				"    img = torch.from_numpy(img.transpose((2, 0, 1)))\n",
				"    \n",
				"    return img.float().div(255)  # 255也可以改为256\n",
				"\n",
				"\n",
				"def _parse_image_function(example_proto, image_feature_description):\n",
				"    # Parse the input tf.train.Example proto using the dictionary above.\n",
				"    return tf.io.parse_single_example(example_proto, image_feature_description)\n",
				"    \n",
				"\n",
				"def train(device, num_classes, val_size, batch_size, lr, optimizer, total_epoch, dataset_path, class_name, model_output_path, pth_path, tensorboard_dir, work_dir, tfrecord_dir):\n",
				"\n",
				"    tfrecord_files = [str(f) for f in Path(tfrecord_dir).glob(\"*.tfrecord\") if f.is_file() and f.stat().st_size > 0]\n",
				"    tf_ds = tf.data.TFRecordDataset(filenames=tfrecord_files)\n",
				"    # use our dataset and defined transformations\n",
				"    dataset = InsSegDataset(get_transform(train=False), tf_ds, class_name, 40)\n",
				"    dataset_test = InsSegDataset(get_transform(train=False), tf_ds, class_name, 40)\n",
				"    # split the dataset in train and test set\n",
				"    indices = torch.randperm(40).tolist()\n",
				"    num_val = int(len(dataset) * val_size)\n",
				"    dataset = torch.utils.data.Subset(dataset, indices[num_val:])  # 训练集张数\n",
				"    dataset_test = torch.utils.data.Subset(dataset_test, indices[:num_val])  # 测试集张数\n",
				"    # define training and validation data loaders\n",
				"    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, collate_fn=utils.collate_fn)\n",
				"    data_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=False, num_workers=4, collate_fn=utils.collate_fn)\n",
				"    # get the model using our helper function\n",
				"    model = get_model_instance_segmentation(num_classes, device, pth_path)\n",
				"    # move model to the right device\n",
				"    model.to(device)\n",
				"\n",
				"    # construct an optimizer\n",
				"    params = [p for p in model.parameters() if p.requires_grad]\n",
				"    if optimizer == 'SGD':\n",
				"        optimizer = torch.optim.SGD(params, lr=lr, momentum=0.9, weight_decay=0.0005)  \n",
				"    else:\n",
				"        optimizer = torch.optim.Adam(params, lr=lr, weight_decay=0.0005)  \n",
				"    # and a learning rate scheduler\n",
				"    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
				"    # let's train it for n epochs\n",
				"    num_epochs = total_epoch  # 训练次数\n",
				"    # 保存模型训练的tensorboard日志\n",
				"    writer = SummaryWriter(log_dir=tensorboard_dir, flush_secs=60)\n",
				"    # if torch.cuda.is_available():\n",
				"    #     graph_inputs = torch.from_numpy(np.random.rand(64, 3, 7, 7)).type(torch.FloatTensor).cuda()\n",
				"    # else:\n",
				"    #     graph_inputs = torch.from_numpy(np.random.rand(64, 3, 7, 7)).type(torch.FloatTensor)\n",
				"    # writer.add_graph(model, (graph_inputs,))\n",
				"\n",
				"    for epoch in range(num_epochs):\n",
				"        metric_logger = train_one_epoch(model, optimizer, data_loader, device, epoch, 10)\n",
				"        print(\"train loss: \", round(metric_logger.loss.global_avg, 3), '  epoch: ', epoch)\n",
				"        train_loss = torch.tensor(round(metric_logger.loss.global_avg, 3)).to(device)\n",
				"        writer.add_scalar('TrainLoss', train_loss, epoch) \n",
				"        # update the learning rate\n",
				"        lr_scheduler.step()\n",
				"        # evaluate on the test dataset\n",
				"        coco_evaluator = evaluate(model, data_loader_test, device=device)\n",
				"        bbox_miou = coco_evaluator.coco_eval['bbox'].stats.mean()\n",
				"        segm_miou = coco_evaluator.coco_eval['segm'].stats.mean()\n",
				"        total_miou = bbox_miou + segm_miou\n",
				"        print(\"eval total miou: \", round(total_miou,3), '  epoch: ', epoch)\n",
				"        total_miou = torch.tensor(round(total_miou,3)).to(device)\n",
				"        writer.add_scalar('EvalTotalMiou', total_miou, epoch) \n",
				"\n",
				"    utils.save_on_master({'model': model.state_dict()}, os.path.join(model_output_path, 'model.pth'))\n",
				"    utils.save_on_master({'model': model.state_dict()}, os.path.join(work_dir, 'pre_training_weights', 'model.pth'))\n",
				"    print(\"That's it!\")\n",
				"\n",
				"    return metric_logger, coco_evaluator\n",
				""
			]
		}
	],
	"nbformat":4
}